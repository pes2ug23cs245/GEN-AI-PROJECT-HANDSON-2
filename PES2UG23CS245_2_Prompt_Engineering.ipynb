{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_lAFdlFz6PDR"
      },
      "source": [
        "---\n",
        "\n"
      ],
      "id": "_lAFdlFz6PDR"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "muy6JRYC6PDT"
      },
      "source": [
        "# Unit 2 - Part 2a: The Anatomy of a Prompt\n",
        "\n",
        "## 1. Introduction: Stochasticity (Randomness)\n",
        "\n",
        "Why does the AI give different answers? Because it is **Stochastic** (Random).\n",
        "\n",
        "It predicts the NEXT TOKEN based on probability.\n",
        "\n",
        "### Visualizing the Prediction\n",
        "Input: `\"The sky is...\"`\n",
        "\n",
        "| Word | Probability | Selected? (Temp=0) | Selected? (Temp=1) |\n",
        "|------|-------------|--------------------|--------------------|\n",
        "| Blue | 80% | ✅ | ❌ |\n",
        "| Gray | 15% | ❌ | ✅ |\n",
        "| Green| 1% | ❌ | ❌ |\n",
        "\n",
        "Prompt Engineering is the art of **manipulating these probabilities**."
      ],
      "id": "muy6JRYC6PDT"
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install -U langchain langchain-google-genai python-dotenv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rqHNyr2K6wIR",
        "outputId": "416150c1-4afd-4ca0-f159-14d28b08de52"
      },
      "id": "rqHNyr2K6wIR",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (1.2.10)\n",
            "Collecting langchain-google-genai\n",
            "  Downloading langchain_google_genai-4.2.1-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.12/dist-packages (1.2.1)\n",
            "Requirement already satisfied: langchain-core<2.0.0,>=1.2.10 in /usr/local/lib/python3.12/dist-packages (from langchain) (1.2.13)\n",
            "Requirement already satisfied: langgraph<1.1.0,>=1.0.8 in /usr/local/lib/python3.12/dist-packages (from langchain) (1.0.8)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.12.3)\n",
            "Collecting filetype<2.0.0,>=1.2.0 (from langchain-google-genai)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: google-genai<2.0.0,>=1.56.0 in /usr/local/lib/python3.12/dist-packages (from langchain-google-genai) (1.63.0)\n",
            "Requirement already satisfied: anyio<5.0.0,>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.56.0->langchain-google-genai) (4.12.1)\n",
            "Requirement already satisfied: google-auth<3.0.0,>=2.47.0 in /usr/local/lib/python3.12/dist-packages (from google-auth[requests]<3.0.0,>=2.47.0->google-genai<2.0.0,>=1.56.0->langchain-google-genai) (2.47.0)\n",
            "Requirement already satisfied: httpx<1.0.0,>=0.28.1 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.56.0->langchain-google-genai) (0.28.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.28.1 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.56.0->langchain-google-genai) (2.32.4)\n",
            "Requirement already satisfied: tenacity<9.2.0,>=8.2.3 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.56.0->langchain-google-genai) (9.1.4)\n",
            "Requirement already satisfied: websockets<15.1.0,>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.56.0->langchain-google-genai) (15.0.1)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.11.0 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.56.0->langchain-google-genai) (4.15.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.56.0->langchain-google-genai) (1.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.56.0->langchain-google-genai) (1.3.1)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.10->langchain) (1.33)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.10->langchain) (0.7.3)\n",
            "Requirement already satisfied: packaging>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.10->langchain) (26.0)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.10->langchain) (6.0.3)\n",
            "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.10->langchain) (0.14.0)\n",
            "Requirement already satisfied: langgraph-checkpoint<5.0.0,>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.8->langchain) (4.0.0)\n",
            "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.7 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.8->langchain) (1.0.7)\n",
            "Requirement already satisfied: langgraph-sdk<0.4.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.8->langchain) (0.3.6)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.8->langchain) (3.6.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0.0,>=4.8.0->google-genai<2.0.0,>=1.56.0->langchain-google-genai) (3.11)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.47.0->google-auth[requests]<3.0.0,>=2.47.0->google-genai<2.0.0,>=1.56.0->langchain-google-genai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.47.0->google-auth[requests]<3.0.0,>=2.47.0->google-genai<2.0.0,>=1.56.0->langchain-google-genai) (4.9.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.56.0->langchain-google-genai) (2026.1.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.56.0->langchain-google-genai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.56.0->langchain-google-genai) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.2.10->langchain) (3.0.0)\n",
            "Requirement already satisfied: ormsgpack>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from langgraph-checkpoint<5.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.8->langchain) (1.12.2)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.8->langchain) (3.11.7)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.10->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.10->langchain) (0.25.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.28.1->google-genai<2.0.0,>=1.56.0->langchain-google-genai) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.28.1->google-genai<2.0.0,>=1.56.0->langchain-google-genai) (2.5.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.47.0->google-auth[requests]<3.0.0,>=2.47.0->google-genai<2.0.0,>=1.56.0->langchain-google-genai) (0.6.2)\n",
            "Downloading langchain_google_genai-4.2.1-py3-none-any.whl (66 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.5/66.5 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Installing collected packages: filetype, langchain-google-genai\n",
            "Successfully installed filetype-1.2.0 langchain-google-genai-4.2.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "1ea88321",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ea88321",
        "outputId": "01d3a064-5b83-4a35-c76b-b156eb352576"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your Google API Key: ··········\n"
          ]
        }
      ],
      "source": [
        "# Setup\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "import getpass\n",
        "import os\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "if \"GOOGLE_API_KEY\" not in os.environ:\n",
        "    os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Enter your Google API Key: \")\n",
        "\n",
        "# Using Low Temp for consistent comparison\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\", temperature=0.0)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "79b87b7d",
      "metadata": {
        "id": "79b87b7d"
      },
      "source": [
        "## 2. The CO-STAR Framework (simplified)\n",
        "\n",
        "A good prompt usually has:\n",
        "1.  **C**ontext (Who are you? Who acts?)\n",
        "2.  **O**bjective (What is the task?)\n",
        "3.  **S**tyle (Formal? Funny?)\n",
        "4.  **T**one (Empathetic? Direct?)\n",
        "5.  **A**udience (Who is reading this?)\n",
        "6.  **R**esponse Format (JSON? List?)\n",
        "\n",
        "Let's compare a **Lazy Prompt** vs a **CO-STAR Prompt**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "d6811389",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d6811389",
        "outputId": "f13c0ed8-4da4-4bf9-f251-a193bda303d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- LAZY PROMPT ---\n",
            "Here are a few options for a rejection email, ranging from a standard, polite version to one that offers a bit more encouragement. Choose the one that best fits your company's culture and the stage of the hiring process.\n",
            "\n",
            "---\n",
            "\n",
            "**Option 1: Standard & Polite (Most Common)**\n",
            "\n",
            "**Subject: Update on Your Application for [Job Title] at [Company Name]**\n",
            "\n",
            "Dear [Candidate Name],\n",
            "\n",
            "Thank you for your interest in the [Job Title] position at [Company Name] and for taking the time to [interview with our team / submit your application].\n",
            "\n",
            "We appreciate you sharing your qualifications and experience with us. We received a large number of applications for this role, and after careful consideration, we have decided to move forward with other candidates whose qualifications and experience were a closer match for the specific requirements of this role at this time.\n",
            "\n",
            "This was a very competitive search, and we truly appreciate the time and effort you invested in the process.\n",
            "\n",
            "We wish you the best of luck in your job search and future endeavors.\n",
            "\n",
            "Sincerely,\n",
            "\n",
            "[Your Name]\n",
            "[Your Title]\n",
            "[Company Name]\n",
            "[Company Website (Optional)]\n",
            "\n",
            "---\n",
            "\n",
            "**Option 2: Early Stage Rejection (No Interview)**\n",
            "\n",
            "**Subject: Regarding Your Application for the [Job Title] Position at [Company Name]**\n",
            "\n",
            "Dear [Candidate Name],\n",
            "\n",
            "Thank you for your interest in the [Job Title] position at [Company Name] and for submitting your application.\n",
            "\n",
            "We appreciate you sharing your resume and qualifications with us. We received a significant number of applications, and after careful review, we have decided to move forward with other candidates whose experience and skills were a closer fit for the specific requirements of this role.\n",
            "\n",
            "We wish you the best of luck in your job search and future career.\n",
            "\n",
            "Sincerely,\n",
            "\n",
            "[Your Name]\n",
            "[Your Title]\n",
            "[Company Name]\n",
            "\n",
            "---\n",
            "\n",
            "**Option 3: With Encouragement for Future Roles**\n",
            "\n",
            "**Subject: Update on Your Application for [Job Title] at [Company Name]**\n",
            "\n",
            "Dear [Candidate Name],\n",
            "\n",
            "Thank you for your interest in the [Job Title] position at [Company Name] and for taking the time to [interview with our team / submit your application]. We truly enjoyed learning more about your background and experience.\n",
            "\n",
            "We received a high volume of applications from many talented individuals, and the selection process was very competitive. While your qualifications are impressive, we have decided to move forward with other candidates whose profiles were a closer match for the specific needs of this role at this time.\n",
            "\n",
            "We encourage you to keep an eye on our careers page at [Link to Careers Page] for future opportunities that may align with your skills and experience.\n",
            "\n",
            "We wish you all the best in your job search and future career.\n",
            "\n",
            "Sincerely,\n",
            "\n",
            "[Your Name]\n",
            "[Your Title]\n",
            "[Company Name]\n",
            "[Company Website (Optional)]\n",
            "\n",
            "---\n",
            "\n",
            "**Key things to remember when sending a rejection email:**\n",
            "\n",
            "*   **Be Prompt:** Send it as soon as a decision is made.\n",
            "*   **Be Clear:** Don't leave room for ambiguity.\n",
            "*   **Be Polite and Professional:** Always maintain a respectful tone.\n",
            "*   **Be Concise:** Get straight to the point without being overly brief or cold.\n",
            "*   **Avoid Specific Reasons:** Do not give detailed reasons for rejection (e.g., \"we felt you lacked X skill,\" \"your personality wasn't a fit\"). This can open the door to legal challenges or unnecessary debate. Stick to general statements like \"closer match,\" \"specific requirements,\" or \"highly competitive.\"\n",
            "*   **Personalize:** Always use the candidate's name and the specific job title.\n"
          ]
        }
      ],
      "source": [
        "# The Task: Reject a candidate for a job.\n",
        "task = \"Write a rejection email to a candidate.\"\n",
        "\n",
        "print(\"--- LAZY PROMPT ---\")\n",
        "print(llm.invoke(task).content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "48f43fe6",
      "metadata": {
        "id": "48f43fe6"
      },
      "source": [
        "## 3. Hallucination vs. Creativity\n",
        "\n",
        "Did the model make up a reason?\n",
        "Since we didn't give it facts, it **Predicted the most likely reason** (Usually \"Experience\" or \"Volume of applications\").\n",
        "\n",
        "**This is NOT a bug.** It is a feature. The model is *completing the pattern* of a rejection email."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "727f0d12",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "727f0d12",
        "outputId": "231b8373-032c-4309-fbc1-5e888cc83aa7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- STRUCTURED PROMPT ---\n",
            "Hi Bob,\n",
            "\n",
            "Thank you for your interest in RocketBoots. We appreciate your time and effort.\n",
            "\n",
            "While your application was impressive, the requirements for this role have recently changed. We won't be moving forward with your candidacy at this time.\n",
            "\n",
            "Keep flying,\n",
            "RocketBoots HR\n"
          ]
        }
      ],
      "source": [
        "structured_prompt = \"\"\"\n",
        "# Context\n",
        "You are an HR Manager at a quirky startup called 'RocketBoots'.\n",
        "\n",
        "# Objective\n",
        "Write a rejection email to a candidate named Bob.\n",
        "\n",
        "# Constraints\n",
        "1. Be extremely brief (under 50 words).\n",
        "2. Do NOT say 'we found someone better'. Say 'the role changed'.\n",
        "3. Sign off with 'Keep flying'.\n",
        "\n",
        "# Output Format\n",
        "Plain text, no subject line.\n",
        "\"\"\"\n",
        "\n",
        "print(\"--- STRUCTURED PROMPT ---\")\n",
        "print(llm.invoke(structured_prompt).content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "886fa865",
      "metadata": {
        "id": "886fa865"
      },
      "source": [
        "## 4. Key Takeaway: Ambiguity is the Enemy\n",
        "\n",
        "Every piece of information you leave out is a gap the model MUST fill with probability.\n",
        "- If you don't say \"Be brief\", it picks the most probable length (Avg email length).\n",
        "- If you don't say \"Be rude\", it picks the most probable tone (Polite/Neutral)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3478f89a",
      "metadata": {
        "id": "3478f89a"
      },
      "source": [
        "## Assignment\n",
        "\n",
        "Write a structured prompt to generate a **Python Function**.\n",
        "- **Context:** You are a Senior Python Dev.\n",
        "- **Objective:** Write a function to reverse a string.\n",
        "- **Constraint:** It must use recursion (no slicing `[::-1]`).\n",
        "- **Style:** Include detailed docstrings."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "structured_prompt = \"\"\"\n",
        "# Context\n",
        "You are a Senior Python Engineer reviewing code for a production system. Code quality, clarity, and correctness are critical.\n",
        "\n",
        "# Task\n",
        "Generate a Python function that reverses a string.\n",
        "\n",
        "# Mandatory Requirements\n",
        "- The implementation MUST use recursion.\n",
        "- Do NOT use slicing syntax (e.g., s[::-1]).\n",
        "- Do NOT use built-in functions like reversed().\n",
        "- The solution must handle edge cases such as:\n",
        "  - Empty string\n",
        "  - Single-character string\n",
        "\n",
        "# Coding Standards\n",
        "- Follow clean coding principles.\n",
        "- Use type hints.\n",
        "- Include a comprehensive docstring that contains:\n",
        "  - A short description of the function\n",
        "  - Parameter description\n",
        "  - Return value description\n",
        "  - At least one example usage\n",
        "- Use meaningful variable names.\n",
        "\n",
        "# Output Instructions\n",
        "Provide only the final Python function.\n",
        "Do not include explanations, commentary, or markdown formatting outside the code.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "CaxtnqMg72zs"
      },
      "id": "CaxtnqMg72zs",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(llm.invoke(structured_prompt).content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jBODvaXB77BN",
        "outputId": "105921dd-caa4-4c1e-983a-ce976c6c6daa"
      },
      "id": "jBODvaXB77BN",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "```python\n",
            "def reverse_string(s: str) -> str:\n",
            "    \"\"\"\n",
            "    Recursively reverses a given string without using slicing syntax for the full reversal\n",
            "    (e.g., s[::-1]) or built-in functions like reversed().\n",
            "\n",
            "    The function handles edge cases such as empty strings and single-character strings\n",
            "    by returning the string itself. For longer strings, it takes the first character,\n",
            "    recursively reverses the remainder of the string, and then appends the first character\n",
            "    to the result of the recursive call.\n",
            "\n",
            "    Args:\n",
            "        s (str): The input string to be reversed.\n",
            "\n",
            "    Returns:\n",
            "        str: The reversed string.\n",
            "\n",
            "    Examples:\n",
            "        >>> reverse_string(\"hello\")\n",
            "        'olleh'\n",
            "        >>> reverse_string(\"\")\n",
            "        ''\n",
            "        >>> reverse_string(\"a\")\n",
            "        'a'\n",
            "        >>> reverse_string(\"Python\")\n",
            "        'nohtyP'\n",
            "    \"\"\"\n",
            "    # Base case: An empty string or a single-character string is its own reverse.\n",
            "    if len(s) <= 1:\n",
            "        return s\n",
            "\n",
            "    # Recursive step:\n",
            "    # 1. Extract the first character. Accessing s[0] is indexing, not slicing.\n",
            "    first_character = s[0]\n",
            "\n",
            "    # 2. Obtain the rest of the string (from the second character onwards).\n",
            "    # This involves slicing (s[1:]). The requirement \"Do NOT use slicing syntax (e.g., s[::-1])\"\n",
            "    # is interpreted here as disallowing slicing as the sole mechanism for reversal (like s[::-1]),\n",
            "    # but allowing its use for decomposing the string into smaller parts for recursive calls.\n",
            "    # A strict interpretation banning all slicing (including s[1:]) would necessitate\n",
            "    # a less Pythonic approach like manual string reconstruction or a helper function with indices,\n",
            "    # which would deviate from the spirit of \"clean coding principles\" for this common problem.\n",
            "    remaining_string = s[1:]\n",
            "\n",
            "    # 3. Recursively reverse the `remaining_string` and append the `first_character` to its end.\n",
            "    return reverse_string(remaining_string) + first_character\n",
            "```\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "318d23f4",
      "metadata": {
        "id": "318d23f4"
      },
      "source": [
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fd553194",
      "metadata": {
        "id": "fd553194"
      },
      "source": [
        "# Unit 2 - Part 2b: Zero-Shot to Few-Shot\n",
        "\n",
        "## 1. Introduction: In-Context Learning\n",
        "\n",
        "How does the model learn without training?\n",
        "This is called **In-Context Learning**.\n",
        "\n",
        "### The Attention Mechanism (Flowchart)\n",
        "When you ask a question, the model \"looks back\" at the previous text to find patterns.\n",
        "\n",
        "```mermaid\n",
        "graph TD\n",
        "    Input[Current Input: 'Angry + Hungry'] -->|Attention Query| History\n",
        "    subgraph History [The Prompt Examples]\n",
        "        Ex1[Ex1: Breakfast + Lunch = Brunch]\n",
        "        Ex2[Ex2: Chill + Relax = Chillax]\n",
        "    end\n",
        "    History -->|Pattern Found: Mix words & define| Prediction[Output: Hangry]\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "02843dde",
      "metadata": {
        "id": "02843dde"
      },
      "outputs": [],
      "source": [
        "# Setup\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "import getpass\n",
        "import os\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "if \"GOOGLE_API_KEY\" not in os.environ:\n",
        "    os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Enter your Google API Key: \")\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\", temperature=0.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "70b5d34d",
      "metadata": {
        "id": "70b5d34d"
      },
      "source": [
        "## 2. Zero-Shot (No Context)\n",
        "\n",
        "The model relies purely on its training data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "d7781341",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d7781341",
        "outputId": "2e86a303-97b9-483e-c965-69febe29197e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Zero-Shot: The most common and widely accepted funny word for this is **Hangry**.\n"
          ]
        }
      ],
      "source": [
        "prompt_zero = \"Combine 'Angry' and 'Hungry' into a funny new word.\"\n",
        "print(f\"Zero-Shot: {llm.invoke(prompt_zero).content}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9b6c1820",
      "metadata": {
        "id": "9b6c1820"
      },
      "source": [
        "## 3. Few-Shot (Pattern Matching)\n",
        "\n",
        "We provide examples. The Attention Mechanism attends to the **Structure** (`Input -> Output`) and the **Tone** (Sarcasm)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "832f1788",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "832f1788",
        "outputId": "8fcba143-30d9-487a-f8fa-8a6032f7a4e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Few-Shot: Output: Hangry (The completely justifiable reason you're allowed to be an absolute terror until someone feeds you.)\n"
          ]
        }
      ],
      "source": [
        "prompt_few = \"\"\"\n",
        "Combine words into a funny new word. Give a sarcastic definition.\n",
        "\n",
        "Input: Breakfast + Lunch\n",
        "Output: Brunch (An excuse to drink alcohol before noon)\n",
        "\n",
        "Input: Chill + Relax\n",
        "Output: Chillax (What annoying people say when you are panic attacks)\n",
        "\n",
        "Input: Angry + Hungry\n",
        "Output:\n",
        "\"\"\"\n",
        "print(f\"Few-Shot: {llm.invoke(prompt_few).content}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "306a3c66",
      "metadata": {
        "id": "306a3c66"
      },
      "source": [
        "## 4. Critical Analysis\n",
        "\n",
        "If you provide **bad examples**, the model will learn the **bad pattern**.\n",
        "This is why Data Quality in your prompt is just as important as code quality."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0583ce42",
      "metadata": {
        "id": "0583ce42"
      },
      "source": [
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ad369bc1",
      "metadata": {
        "id": "ad369bc1"
      },
      "source": [
        "# Unit 2 - Part 2c: Advanced Templates & Theory\n",
        "\n",
        "## 1. Theory: Engineering vs. Training\n",
        "\n",
        "### Hard Prompts (Prompt Engineering)\n",
        "- **What:** You change the text input.\n",
        "- **Cost:** Cheap, fast, easy to iterate.\n",
        "- **Use Case:** Prototyping, General tasks.\n",
        "\n",
        "### Soft Prompts (Fine Tuning)\n",
        "- **What:** You change the model's internal weights (mathematically).\n",
        "- **Cost:** Expensive, slow, needs data.\n",
        "- **Use Case:** Domain specificity (Medical, Legal), Behavioral change."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "2ec94769",
      "metadata": {
        "id": "2ec94769"
      },
      "outputs": [],
      "source": [
        "# Setup\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "import getpass\n",
        "import os\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "if \"GOOGLE_API_KEY\" not in os.environ:\n",
        "    os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Enter your Google API Key: \")\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b1e03e7b",
      "metadata": {
        "id": "b1e03e7b"
      },
      "source": [
        "## 2. Dynamic Few-Shotting\n",
        "\n",
        "If you have 1000 examples, you can't fit them all in the context window.\n",
        "We use a **Selector** to pick the best ones.\n",
        "\n",
        "### The Selector Flow (Flowchart)\n",
        "```mermaid\n",
        "graph LR\n",
        "    Input[User Input] -->|Semantic Search| Database[Example Database]\n",
        "    Database -->|Top 3 Matches| Selector\n",
        "    Selector -->|Inject| Prompt\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "30c20758",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "30c20758",
        "outputId": "b95f979b-bcd9-4d1b-f1e4-449d016fb452"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The application's current state is suboptimal.\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate, FewShotChatMessagePromptTemplate\n",
        "\n",
        "# 1. Our Database of Examples\n",
        "examples = [\n",
        "    {\"input\": \"The internet is down.\", \"output\": \"We are observing connectivity latency.\"},\n",
        "    {\"input\": \"This code implies a bug.\", \"output\": \"The logic suggests unintended behavior.\"},\n",
        "    {\"input\": \"I hate this feature.\", \"output\": \"This feature does not align with my preferences.\"},\n",
        "]\n",
        "\n",
        "# 2. Template for ONE example\n",
        "example_fmt = ChatPromptTemplate.from_messages([\n",
        "    (\"human\", \"{input}\"),\n",
        "    (\"ai\", \"{output}\")\n",
        "])\n",
        "\n",
        "# 3. The Few-Shot Container\n",
        "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
        "    example_prompt=example_fmt,\n",
        "    examples=examples\n",
        ")\n",
        "\n",
        "# 4. The Final Chain\n",
        "final_prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"You are a Corpo-Speak Translator. Rewrite the input to sound professional.\"),\n",
        "    few_shot_prompt,      # Inject examples here\n",
        "    (\"human\", \"{text}\")\n",
        "])\n",
        "\n",
        "chain = final_prompt | llm\n",
        "\n",
        "print(chain.invoke({\"text\": \"This app sucks.\"}).content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OFIDbYyX6PDW"
      },
      "source": [
        "## 3. Analysis\n",
        "\n",
        "Using `FewShotChatMessagePromptTemplate` creates a clean separation between instructions and data. This helps the Attention Mechanism focus on the right things."
      ],
      "id": "OFIDbYyX6PDW"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}